{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "058e820d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\oswme\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\oswme\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca5e21b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "value = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66dd2458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to process a TREC file and write the result to another file\n",
    "def process_trec_file(input_file, output_file):\n",
    "    # Open the input file for reading and the output file for writing\n",
    "    with open(input_file, 'r', encoding='utf-8') as infile, open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        # Loop through each line in the input file\n",
    "        for line in infile:\n",
    "            # Remove <TEXT> and </TEXT> tags\n",
    "            line = re.sub(r'<TEXT>|</TEXT>|<DOC>|</DOC>', '', line)\n",
    "\n",
    "            # Replace symbols and numbers with spaces\n",
    "            line = re.sub(r'[^a-zA-Z\\s]', ' ', line)\n",
    "            \n",
    "            # Convert the line to lowercase\n",
    "            line = line.lower()\n",
    "            \n",
    "            # Tokenize the line into words\n",
    "            tokens = word_tokenize(line)\n",
    "            \n",
    "            # Remove stop words from the list of tokens\n",
    "            filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "            # Join the filtered tokens into a string\n",
    "            filtered_line = ' '.join(filtered_tokens)\n",
    "            \n",
    "            # Write the processed line to the output file\n",
    "            outfile.write(filtered_line + '\\n')\n",
    "\n",
    "# Check if the script is being run as the main program\n",
    "if __name__ == \"__main__\":\n",
    "    # Define input and output file paths based on a variable 'value'\n",
    "    input_file_path = f'trecFiles/cluster_{value}_output.trec'\n",
    "    output_file_path = f'trecFiles/{value}.txt'\n",
    "     # Call the process_trec_file function with the specified file paths \n",
    "    process_trec_file(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f021bd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def read_trec_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        # Read the entire content of the TREC file\n",
    "        content = file.read()\n",
    "        # Split the content into words\n",
    "        words = content.split()\n",
    "    return words\n",
    "\n",
    "def generate_random_word_pairs(words, num_pairs):\n",
    "    # Ensure there are enough words to generate pairs\n",
    "    if len(words) < 2:\n",
    "        raise ValueError(\"Insufficient words to generate pairs\")\n",
    "\n",
    "    # Generate random word pairs\n",
    "    random_pairs = random.sample(list(zip(words, words[1:])), min(num_pairs, len(words)-1))\n",
    "\n",
    "    return random_pairs\n",
    "\n",
    "def write_word_pairs_to_file(pairs, output_file):\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        for pair in pairs:\n",
    "            file.write(f\"{pair[0]} {pair[1]}\\n\")\n",
    "\n",
    "# Example usage\n",
    "trec_file_path = f'trecFiles/{value}.txt'\n",
    "output_file_path = f'tests/{value}.txt'\n",
    "number_of_pairs = 100\n",
    "\n",
    "# Read the TREC file\n",
    "words = read_trec_file(trec_file_path)\n",
    "\n",
    "# Generate random word pairs\n",
    "random_pairs = generate_random_word_pairs(words, number_of_pairs)\n",
    "\n",
    "# Write word pairs to a text file\n",
    "write_word_pairs_to_file(random_pairs, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1fa0926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine All text case files\n",
    "def combine_text_files(input_files, output_file):\n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        for input_file in input_files:\n",
    "            with open(input_file, 'r', encoding='utf-8') as infile:\n",
    "                outfile.write(infile.read())\n",
    "                # Add a newline between the contents of each file\n",
    "                outfile.write('\\n')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file_paths = ['tests/0.txt', 'tests/1.txt', 'tests/2.txt', 'tests/3.txt', 'tests/4.txt', 'tests/5.txt', 'tests/6.txt', 'tests/7.txt']\n",
    "    output_file_path = 'tests/combined_output.txt'\n",
    "\n",
    "    combine_text_files(input_file_paths, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4e1652",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
