{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6db0754",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T01:32:49.216880Z",
     "start_time": "2023-12-25T01:32:49.213964Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fec70f3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T01:28:14.326224Z",
     "start_time": "2023-12-25T01:28:07.524743Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = Path(\"modified_0002.pkl\")\n",
    "\n",
    "# Open the Parquet file\n",
    "df = pd.read_pickle(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb8fffb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the embeddings\n",
    "normalized_embeddings = normalize(df['emb'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34a4cefc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T01:28:14.334282Z",
     "start_time": "2023-12-25T01:28:14.329811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size of vector (253344, 1024)\n",
      "Original size of vector (253344, 256)\n"
     ]
    }
   ],
   "source": [
    "# Dimensionality Reduction using PCA\n",
    "pca_components = 256\n",
    "pca = PCA(n_components=pca_components)\n",
    "\n",
    "print(f\"Original size of vector {normalized_embeddings.shape}\")\n",
    "\n",
    "# normalised embeddings are showing a type misamtch. Don't know how to fix it\n",
    "PCA_reduced_embeddings = pca.fit_transform(normalized_embeddings)\n",
    "\n",
    "print(f\"Original size of vector {PCA_reduced_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0607180",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T01:28:14.343779Z",
     "start_time": "2023-12-25T01:28:14.334999Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oswme\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "# K Means Clustring \n",
    "num_clusters = 8  # Adjust the number of clusters\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(PCA_reduced_embeddings)\n",
    "\n",
    "df['cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0644ff7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T01:28:14.439401Z",
     "start_time": "2023-12-25T01:28:14.345110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    51034\n",
       "0    46739\n",
       "1    35165\n",
       "2    33402\n",
       "6    25844\n",
       "7    23905\n",
       "3    23049\n",
       "4    14206\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30f46310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  title  cluster\n",
      "0     1        3\n",
      "1     2        0\n",
      "2     3        5\n",
      "3     4        2\n",
      "4     5        5\n"
     ]
    }
   ],
   "source": [
    "df.drop('emb', axis=1, inplace=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42380b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title                                                    1\n",
      "text     If you know the application which can open 000...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "file_path = Path(\"modified_text_0002.pkl\")\n",
    "\n",
    "# Open the Parquet file\n",
    "df_text = pd.read_pickle(file_path)\n",
    "print(df_text.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2555a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df, df_text, on='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "572ce293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title                                                      1\n",
      "cluster                                                    3\n",
      "text       If you know the application which can open 000...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61cdaeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_clusters = merged_df['cluster'].unique()\n",
    "\n",
    "# Create separate DataFrames for each cluster\n",
    "cluster_dataframes = {}\n",
    "\n",
    "for cluster in unique_clusters:\n",
    "    cluster_dataframes[cluster] = merged_df[merged_df['cluster'] == cluster][['title', 'text']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4845e79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(cluster_dataframes[7].head())\n",
    "# for index, row in cluster_df.iterrows():\n",
    "#     print(row['title'])\n",
    "#     print(row['text'])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e64a251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TREC file for Cluster 3 created: trecFiles/cluster_3_output.trec\n",
      "TREC file for Cluster 0 created: trecFiles/cluster_0_output.trec\n",
      "TREC file for Cluster 5 created: trecFiles/cluster_5_output.trec\n",
      "TREC file for Cluster 2 created: trecFiles/cluster_2_output.trec\n",
      "TREC file for Cluster 7 created: trecFiles/cluster_7_output.trec\n",
      "TREC file for Cluster 1 created: trecFiles/cluster_1_output.trec\n",
      "TREC file for Cluster 4 created: trecFiles/cluster_4_output.trec\n",
      "TREC file for Cluster 6 created: trecFiles/cluster_6_output.trec\n"
     ]
    }
   ],
   "source": [
    "#Save new clusters as a trec files.\n",
    "for cluster, cluster_df in cluster_dataframes.items():\n",
    "    trec_filename = f'trecFiles/cluster_{cluster}_output.trec'\n",
    "\n",
    "    with open(trec_filename, 'w', encoding='utf-8') as trec_file:\n",
    "        for index, row in cluster_df.iterrows():\n",
    "            # Write TREC format for each document\n",
    "            trec_file.write(f\"<DOC>\\n\")\n",
    "            trec_file.write(f\"<TEXT>\\n{row['title']}\\n\")\n",
    "            trec_file.write(f\"{row['text']}\\n</TEXT>\\n\")\n",
    "            trec_file.write(f\"</DOC>\\n\")\n",
    "\n",
    "    print(f\"TREC file for Cluster {cluster} created: {trec_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fa1169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
