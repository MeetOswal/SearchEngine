{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6db0754",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T01:32:49.216880Z",
     "start_time": "2023-12-25T01:32:49.213964Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fec70f3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T01:28:14.326224Z",
     "start_time": "2023-12-25T01:28:07.524743Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = Path(\"modified_0002.pkl\")\n",
    "\n",
    "# Open the Parquet file\n",
    "df = pd.read_pickle(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb8fffb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the embeddings\n",
    "normalized_embeddings = normalize(df['emb'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34a4cefc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T01:28:14.334282Z",
     "start_time": "2023-12-25T01:28:14.329811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size of vector (253344, 256)\n"
     ]
    }
   ],
   "source": [
    "# Dimensionality Reduction using PCA\n",
    "pca_components = 256\n",
    "pca = PCA(n_components=pca_components)\n",
    "\n",
    "# normalised embeddings are showing a type misamtch. Don't know how to fix it\n",
    "PCA_reduced_embeddings = pca.fit_transform(normalized_embeddings)\n",
    "\n",
    "print(f\"Original size of vector {PCA_reduced_embeddings.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0607180",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T01:28:14.343779Z",
     "start_time": "2023-12-25T01:28:14.334999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization 0\n",
      "  Iteration 10\n",
      "  Iteration 20\n",
      "  Iteration 30\n",
      "  Iteration 40\n",
      "Initialization converged: True\n"
     ]
    }
   ],
   "source": [
    "num_clusters = 8\n",
    "\n",
    "# Fit a Gaussian Mixture Model with 8 components and enable verbose output\n",
    "gmm = GaussianMixture(n_components=num_clusters, random_state=0, verbose=1)\n",
    "gmm.fit(PCA_reduced_embeddings)\n",
    "\n",
    "# Assign cluster labels to data points\n",
    "cluster_labels = gmm.predict(PCA_reduced_embeddings)\n",
    "\n",
    "# Add cluster labels to the DataFrame\n",
    "df['cluster'] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0644ff7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T01:28:14.439401Z",
     "start_time": "2023-12-25T01:28:14.345110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    49633\n",
       "3    45758\n",
       "0    38744\n",
       "4    32854\n",
       "2    29020\n",
       "7    24622\n",
       "5    19534\n",
       "1    13179\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30f46310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  title  cluster\n",
      "0     1        7\n",
      "1     2        0\n",
      "2     3        3\n",
      "3     4        5\n",
      "4     5        3\n"
     ]
    }
   ],
   "source": [
    "df.drop('emb', axis=1, inplace=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42380b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title                                                    1\n",
      "text     If you know the application which can open 000...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "file_path = Path(\"modified_text_0002.pkl\")\n",
    "\n",
    "# Open the Parquet file\n",
    "df_text = pd.read_pickle(file_path)\n",
    "print(df_text.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2555a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df, df_text, on='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "572ce293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title                                                      1\n",
      "emb        [0.055311203, -0.17642975, 0.20465851, -0.0252...\n",
      "cluster                                                    7\n",
      "text       If you know the application which can open 000...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61cdaeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_clusters = merged_df['cluster'].unique()\n",
    "\n",
    "# Create separate DataFrames for each cluster\n",
    "cluster_dataframes = {}\n",
    "\n",
    "for cluster in unique_clusters:\n",
    "    cluster_dataframes[cluster] = merged_df[merged_df['cluster'] == cluster][['title', 'text']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4845e79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(cluster_dataframes[7].head())\n",
    "# for index, row in cluster_df.iterrows():\n",
    "#     print(row['title'])\n",
    "#     print(row['text'])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e64a251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TREC file for Cluster 7 created: trecFiles/cluster_7_output.trec\n",
      "TREC file for Cluster 4 created: trecFiles/cluster_4_output.trec\n",
      "TREC file for Cluster 3 created: trecFiles/cluster_3_output.trec\n",
      "TREC file for Cluster 0 created: trecFiles/cluster_0_output.trec\n",
      "TREC file for Cluster 6 created: trecFiles/cluster_6_output.trec\n",
      "TREC file for Cluster 5 created: trecFiles/cluster_5_output.trec\n",
      "TREC file for Cluster 2 created: trecFiles/cluster_2_output.trec\n",
      "TREC file for Cluster 1 created: trecFiles/cluster_1_output.trec\n"
     ]
    }
   ],
   "source": [
    "#Save new clusters as a trec files.\n",
    "for cluster, cluster_df in cluster_dataframes.items():\n",
    "    trec_filename = f'trecFiles/cluster_{cluster}_output.trec'\n",
    "\n",
    "    with open(trec_filename, 'w', encoding='utf-8') as trec_file:\n",
    "        for index, row in cluster_df.iterrows():\n",
    "            # Write TREC format for each document\n",
    "            trec_file.write(f\"<DOC>\\n\")\n",
    "            trec_file.write(f\"<TEXT>\\n{row['title']}\\n\")\n",
    "            trec_file.write(f\"{row['text']}\\n</TEXT>\\n\")\n",
    "            trec_file.write(f\"</DOC>\\n\")\n",
    "\n",
    "    print(f\"TREC file for Cluster {cluster} created: {trec_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fa1169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
